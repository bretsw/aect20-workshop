---
title: "1-setting-up-demo-doc"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let's first load the {dataedu} package adn the {tidyverse} suite of packages.

We'll also load the {tidytext} package

```{r}
library(dataedu)
library(tidyverse)
library(tidytext)
```

If you saw some messages, success!

Here is the data set we will use:

```{r}
tt_tweets
```

# Text analysis

Prepare data for analysis by filtering, selecting key variables, and processing the status ID variable.

```{r}
tweets <-
  raw_tweets %>%
  #filter for English tweets
  filter(lang == "en") %>%
  select(status_id, text) %>%
  # Convert the ID field to the character data type
  mutate(status_id = as.character(status_id))
```

Tokenize tweets. 

```{r}
tokens <- 
  tweets %>%
  unnest_tokens(output = word, input = text)
```

Remove stopwords---common words.

```{r}
data(stop_words)

tokens <-
  tokens %>%
  anti_join(stop_words, by = "word")
```

Calculate common words

```{r}
tokens %>%
  count(word, sort = TRUE) %>%
  # n as a percent of total words
  mutate(percent = n / sum(n) * 100)
```
